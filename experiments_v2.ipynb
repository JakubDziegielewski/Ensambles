{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZUM - Projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import potrzebnych narzędzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import przygotowanej klasy Ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ensembles import Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan badań\n",
    "1. Modele zespołowe dla każdego z algorytmów (SVC, DecisionTreeClassifier,  CategoricalNB, GaussianNB)\n",
    "2. Dla każdego z modelów zespołowych testy dla 5, 10, 50, 100 modeli w zespole.\n",
    "3. Analogiczne testy dla Bagging Classifier\n",
    "4. Analogiczne testy dla Random Forest Classifier (liczba drzew)\n",
    "5. Testy na algorytmach konwencjonalnych\n",
    "6. Wszystko wyżej dla CV = 10\n",
    "7. Wszystko wyżej powtórzone dla dwóch zbiorów danych.\n",
    "\n",
    "** dodatkowo różne opcje podzialu atrybutow na modele w modelach zespolowych\n",
    "\n",
    "w sumie (4*4 + 4*4 + 4 + 4)*2 = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt(\"human_activity/X_train.txt\", dtype = float)\n",
    "x_test = np.loadtxt(\"human_activity/X_test.txt\", dtype = float)\n",
    "y_train = np.loadtxt(\"human_activity/y_train.txt\", dtype = int)\n",
    "y_test = np.loadtxt(\"human_activity/y_test.txt\", dtype = int)\n",
    "\n",
    "x = np.vstack([x_train, x_test])\n",
    "y = np.append(y_train, y_test)\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(\n",
    "#    x, y, test_size=0.99, random_state=random_state\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja pomocnicza do dyskretyzacji danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intervals(x_train, group_vector):  # auxilary values for data disrcetization\n",
    "    intervals = np.array([np.zeros(i - 1) for i in group_vector])\n",
    "\n",
    "    for i, features in enumerate(x_train.T):\n",
    "        max_value = max(features)\n",
    "        min_value = min(features)\n",
    "        section_size = (max_value - min_value) / group_vector[i]\n",
    "        intervals[i] = np.array(\n",
    "            [min_value + section_size * j for j in range(1, group_vector[i])]\n",
    "        )\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na pojedynczych modelach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier CV scores: [0.97087379 0.93106796 0.87864078 0.94660194 0.96990291 0.97378641\n",
      " 0.96116505 0.95631068 0.95339806 0.96793003]\n",
      "Decision Tree Classifier CV mean score:\n",
      "0.9509677601970055\n"
     ]
    }
   ],
   "source": [
    "clf_svc = SVC()\n",
    "clf_svc.fit(x_train, y_train)\n",
    "score =  clf_svc.score(x_test, y_test)\n",
    "svc_scores = cross_val_score(clf_svc, x, y, cv=10)\n",
    "print(\"Decision Tree Classifier CV scores:\", svc_scores)\n",
    "print(\"Decision Tree Classifier CV mean score:\")\n",
    "print(svc_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier CV scores: [0.76504854 0.68640777 0.57669903 0.75436893 0.68349515 0.7038835\n",
      " 0.78640777 0.79223301 0.81456311 0.69776482]\n",
      "Decision Tree Classifier CV mean score:\n",
      "0.7260871616330304\n"
     ]
    }
   ],
   "source": [
    "clf_gaussNB = GaussianNB()\n",
    "clf_gaussNB.fit(x_train, y_train)\n",
    "score =  clf_gaussNB.score(x_test, y_test)\n",
    "gaussNB_scores = cross_val_score(clf_gaussNB, x, y, cv=10)\n",
    "print(\"Decision Tree Classifier CV scores:\", gaussNB_scores)\n",
    "print(\"Decision Tree Classifier CV mean score:\")\n",
    "print(gaussNB_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = find_intervals(x_train, [4] * 561)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T\n",
    "x_discrete = np.vstack([x_train_discrete, x_test_discrete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_discrete shape: (10299, 561)\n",
      "y shape: (10299,)\n",
      "Feature 0 unique values in x_discrete: [0 1 2 3]\n",
      "Feature 1 unique values in x_discrete: [0 1 2 3]\n",
      "Feature 2 unique values in x_discrete: [0 1 2 3]\n",
      "Feature 3 unique values in x_discrete: [0 1 2 3]\n",
      "Feature 4 unique values in x_discrete: [0 1 2 3]\n",
      "y unique: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_discrete shape:\", x_discrete.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "for i in range(5):  # Change the range as needed to inspect more features\n",
    "    unique_values = np.unique(x_discrete[:, i])\n",
    "    print(f\"Feature {i} unique values in x_discrete: {unique_values}\")\n",
    "print(\"y unique:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_catNB = CategoricalNB()\n",
    "clf_catNB.fit(x_train_discrete, y_train)\n",
    "score =  clf_catNB.score(x_discrete, y)\n",
    "print(score)\n",
    "catNB_scores = cross_val_score(clf_catNB, x_discrete, y, cv=10)\n",
    "print(\"Categorical NB CV scores:\", catNB_scores)\n",
    "print(\"Categorical NB CV mean score:\")\n",
    "print(catNB_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier CV scores: [0.89223301 0.84368932 0.80970874 0.8592233  0.88058252 0.89708738\n",
      " 0.90097087 0.81553398 0.9        0.88435374]\n",
      "Decision Tree Classifier CV mean score:\n",
      "0.8683382867710192\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(x_train, y_train)\n",
    "score =  clf_dt.score(x_test, y_test)\n",
    "dt_scores = cross_val_score(clf_dt, x, y, cv=10)\n",
    "print(\"Decision Tree Classifier CV scores:\", dt_scores)\n",
    "print(\"Decision Tree Classifier CV mean score:\")\n",
    "print(dt_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na modelach zespołowych z biblioteki scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier CV scores: [0.92815534 0.92524272 0.85533981 0.94757282 0.88834951 0.95339806\n",
      " 0.93786408 0.9038835  0.93592233 0.94071914]\n",
      "RandomForestClassifier CV mean score:\n",
      "0.9216447300140583\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=10, random_state=random_state)\n",
    "clf_rf.fit(x_train, y_train)\n",
    "score =  clf_rf.score(x_test, y_test)\n",
    "rf_scores = cross_val_score(clf_rf, x, y, cv=10)\n",
    "print(\"RandomForestClassifier CV scores:\", rf_scores)\n",
    "print(\"RandomForestClassifier CV mean score:\")\n",
    "print(rf_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baggin Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier with SVC estimator CV scores: [0.97184466 0.92815534 0.87669903 0.94466019 0.96893204 0.97378641\n",
      " 0.95825243 0.95825243 0.95048544 0.96112731]\n",
      "Bagging Classifier with SVC estimator CV mean score:\n",
      "0.9492195269231134\n"
     ]
    }
   ],
   "source": [
    "clf_bag_svc = BaggingClassifier(estimator=SVC(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_svc.fit(x_train, y_train)\n",
    "score =  clf_bag_svc.score(x_test, y_test)\n",
    "bag_svc_scores = cross_val_score(clf_bag_svc, x, y, cv=10)\n",
    "print(\"Bagging Classifier with SVC estimator CV scores:\", bag_svc_scores)\n",
    "print(\"Bagging Classifier with SVC estimator CV mean score:\")\n",
    "print(bag_svc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier with Decision Tree estimator CV scores: [0.91359223 0.89029126 0.82815534 0.92038835 0.93883495 0.95825243\n",
      " 0.90679612 0.84854369 0.90097087 0.9271137 ]\n",
      "Bagging Classifier with Decision Tree estimator CV mean score:\n",
      "0.9032938945342351\n"
     ]
    }
   ],
   "source": [
    "clf_bag_dt = BaggingClassifier(estimator=DecisionTreeClassifier(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_dt.fit(x_train, y_train)\n",
    "score =  clf_bag_dt.score(x_test, y_test)\n",
    "bag_dt_scores = cross_val_score(clf_bag_dt, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", bag_dt_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(bag_dt_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = find_intervals(x_train, [4] * 561)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T\n",
    "x_discrete = np.vstack([x_train_discrete, x_test_discrete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8724126230064473\n"
     ]
    }
   ],
   "source": [
    "clf_bag_catNB = BaggingClassifier(estimator=CategoricalNB(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_catNB.fit(x_train_discrete, y_train)\n",
    "score = clf_bag_catNB.score(x_test_discrete, y_test)\n",
    "print(score)\n",
    "bag_catNB_scores = cross_val_score(clf_bag_catNB, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Categorical NB estimator CV scores:\", bag_catNB_scores)\n",
    "print(\"Bagging Classifier with Categorical NB estimator CV mean score:\")\n",
    "print(bag_catNB_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8082796063793688\n",
      "Bagging Classifier with Decision Tree estimator CV scores: [0.76213592 0.67864078 0.58543689 0.75631068 0.68834951 0.70291262\n",
      " 0.8        0.79223301 0.83786408 0.70456754]\n",
      "Bagging Classifier with Decision Tree estimator CV mean score:\n",
      "0.7308451036447867\n"
     ]
    }
   ],
   "source": [
    "clf_bag_gaussNB = BaggingClassifier(estimator=GaussianNB(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_gaussNB.fit(x_train, y_train)\n",
    "score = clf_bag_gaussNB.score(x_test, y_test)\n",
    "print(score)\n",
    "bag_gaussNB_scores = cross_val_score(clf_bag_gaussNB, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", bag_gaussNB_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(bag_gaussNB_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na przygotowanej implementacji modeli zespołowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764845605700713\n"
     ]
    }
   ],
   "source": [
    "clf_ens_svc = Ensemble(\n",
    "    SVC, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_svc.fit(x_train, y_train)\n",
    "score = clf_ens_svc.score(x_test, y_test)\n",
    "print(score)\n",
    "ens_svc_scores = cross_val_score(clf_ens_svc, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", ens_svc_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(ens_svc_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7366813708856464\n"
     ]
    }
   ],
   "source": [
    "clf_ens_gaussNB = Ensemble(\n",
    "    GaussianNB, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_gaussNB.fit(x_train, y_train)\n",
    "score = clf_ens_gaussNB.score(x_test, y_test)\n",
    "print(score)\n",
    "ens_gaussNB_scores = cross_val_score(clf_ens_gaussNB, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", ens_gaussNB_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(ens_gaussNB_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Naive Bayes for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = find_intervals(x_train, [4] * 561)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T\n",
    "x_discrete = np.vstack([x_train_discrete, x_test_discrete])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8218527315914489\n"
     ]
    }
   ],
   "source": [
    "clf_ens_catNB = Ensemble(\n",
    "    CategoricalNB, 10, random_state=random_state, min_categories=[4] * 561\n",
    ")\n",
    "clf_ens_catNB.fit(x_train_discrete, y_train)\n",
    "score = clf_ens_catNB.score(x_test_discrete, y_test)\n",
    "print(score)\n",
    "ens_catNB_scores = cross_val_score(clf_ens_catNB, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", ens_catNB_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(ens_catNB_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8676620291822192\n",
      "[0.91407767 0.89514563 0.92135922 0.90436893 0.89266634]\n"
     ]
    }
   ],
   "source": [
    "clf_ens_dt = Ensemble(\n",
    "    DecisionTreeClassifier, 10, max_attributes= 30, random_state=random_state\n",
    ")\n",
    "clf_ens_dt.fit(x_train, y_train)\n",
    "score = clf_ens_dt.score(x_test, y_test)\n",
    "print(score)\n",
    "ens_dt_scores = cross_val_score(clf_ens_dt, x, y, cv=10)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV scores:\", ens_dt_scores)\n",
    "print(\"Bagging Classifier with Decision Tree estimator CV mean score:\")\n",
    "print(ens_dt_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8680013573125213\n"
     ]
    }
   ],
   "source": [
    "clf_ens_svc = Ensemble(\n",
    "    DecisionTreeClassifier, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_svc.fit(x_train, y_train)\n",
    "score = clf_ens_svc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
