{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZUM - Projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import potrzebnych narzędzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import przygotowanej klasy Ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ensembles import Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan badań\n",
    "1. Modele zespołowe dla każdego z algorytmów (SVC, DecisionTreeClassifier,  CategoricalNB, GaussianNB)\n",
    "2. Dla każdego z modelów zespołowych testy dla 5, 10, 50, 100 modeli w zespole.\n",
    "3. Analogiczne testy dla Bagging Classifier\n",
    "4. Analogiczne testy dla Random Forest Classifier (liczba drzew)\n",
    "5. Testy na algorytmach konwencjonalnych\n",
    "6. Wszystko wyżej dla CV = 10\n",
    "7. Wszystko wyżej powtórzone dla dwóch zbiorów danych.\n",
    "\n",
    "** dodatkowo różne opcje podzialu atrybutow na modele w modelach zespolowych\n",
    "\n",
    "w sumie (4*4 + 4*4 + 4 + 4)*2 = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt(\"human_activity/X_train.txt\", dtype = float)\n",
    "x_test = np.loadtxt(\"human_activity/X_test.txt\", dtype = float)\n",
    "y_train = np.loadtxt(\"human_activity/y_train.txt\", dtype = int)\n",
    "y_test = np.loadtxt(\"human_activity/y_test.txt\", dtype = int)\n",
    "\n",
    "x = np.vstack([x_train, x_test])\n",
    "y = np.append(y_train, y_test)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(\n",
    "#    x, y, test_size=0.99, random_state=random_state\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja pomocnicza do dyskretyzacji danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intervals(x_train, group_vector):  # auxilary values for data disrcetization\n",
    "    intervals = np.array([np.zeros(i - 1) for i in group_vector])\n",
    "\n",
    "    for i, features in enumerate(x_train.T):\n",
    "        max_value = max(features)\n",
    "        min_value = min(features)\n",
    "        section_size = (max_value - min_value) / group_vector[i]\n",
    "        intervals[i] = np.array(\n",
    "            [min_value + section_size * j for j in range(1, group_vector[i])]\n",
    "        )\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na pojedynczych modelach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC()\n",
    "clf_svc.fit(x_train, y_train)\n",
    "score = clf_svc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gaussNB = GaussianNB()\n",
    "clf_gaussNB.fit(x_train, y_train)\n",
    "score =  clf_gaussNB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = find_intervals(x_train, [4] * 30)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_catNB = CategoricalNB()\n",
    "clf_catNB.fit(x_train_discrete, y_train)\n",
    "score =  clf_catNB.score(x_test_discrete, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(x_train, y_train)\n",
    "score = clf_dt.score(x_test, y_test)\n",
    "print(score)\n",
    "scores = cross_val_score(clf_dt, x, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na modelach zespołowych z biblioteki scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=10, random_state=random_state)\n",
    "clf_rf.fit(x_train, y_train)\n",
    "score = clf_rf.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baggin Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9501187648456056\n"
     ]
    }
   ],
   "source": [
    "clf_bag_svc = BaggingClassifier(estimator=SVC(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_svc.fit(x_train, y_train)\n",
    "score = clf_bag_svc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8808958262639973\n"
     ]
    }
   ],
   "source": [
    "clf_bag_dt = BaggingClassifier(estimator=DecisionTreeClassifier(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_dt.fit(x_train, y_train)\n",
    "score = clf_bag_dt.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m intervals \u001b[38;5;241m=\u001b[39m \u001b[43mfind_intervals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m x_train_discrete \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mdigitize(column , bins\u001b[38;5;241m=\u001b[39mintervals[i]) \u001b[38;5;28;01mfor\u001b[39;00m i, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mT)])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      3\u001b[0m x_test_discrete \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mdigitize(column , bins\u001b[38;5;241m=\u001b[39mintervals[i]) \u001b[38;5;28;01mfor\u001b[39;00m i, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x_test\u001b[38;5;241m.\u001b[39mT)])\u001b[38;5;241m.\u001b[39mT\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mfind_intervals\u001b[1;34m(x_train, group_vector)\u001b[0m\n\u001b[0;32m      5\u001b[0m     max_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(features)\n\u001b[0;32m      6\u001b[0m     min_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(features)\n\u001b[1;32m----> 7\u001b[0m     section_size \u001b[38;5;241m=\u001b[39m (max_value \u001b[38;5;241m-\u001b[39m min_value) \u001b[38;5;241m/\u001b[39m \u001b[43mgroup_vector\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m     intervals[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m      9\u001b[0m         [min_value \u001b[38;5;241m+\u001b[39m section_size \u001b[38;5;241m*\u001b[39m j \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, group_vector[i])]\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m intervals\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "intervals = find_intervals(x_train, [4] * 30)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bag_catNB = CategoricalNB(estimator=SVC(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_catNB.fit(x_train, y_train)\n",
    "score = clf_bag_catNB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bag_gaussNB = GaussianNB(estimator=SVC(),n_estimators=10, random_state=random_state)\n",
    "clf_bag_gaussNB.fit(x_train, y_train)\n",
    "score = clf_bag_gaussNB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testy na przygotowanej implementacji modeli zespołowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ens_svc = Ensemble(\n",
    "    SVC, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_svc.fit(x_train, y_train)\n",
    "score = clf_ens_svc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ens_gaussNB = Ensemble(\n",
    "    GaussianNB, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_gaussNB.fit(x_train, y_train)\n",
    "score = clf_ens_gaussNB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Naive Bayes for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = find_intervals(x_train, [4] * 30)\n",
    "x_train_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_train.T)]).T\n",
    "x_test_discrete = np.array([np.digitize(column , bins=intervals[i]) for i, column in enumerate(x_test.T)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ens_catNB = Ensemble(\n",
    "    CategoricalNB, 10, random_state=random_state, min_categories=[4] * 30\n",
    ")\n",
    "clf_ens_catNB.fit(x_train_discrete, y_train)\n",
    "score = clf_ens_catNB.score(x_test_discrete, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zespołowy modeli Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "[0.88883495 0.82864078 0.87330097 0.8592233  0.87178242]\n",
      "0.8639294197488971\n",
      "[0.90631068 0.88737864 0.9131068  0.90679612 0.89218067]\n"
     ]
    }
   ],
   "source": [
    "clf_ens_dt = Ensemble(\n",
    "    DecisionTreeClassifier, 10, max_attributes= 30, random_state=random_state\n",
    ")\n",
    "clf_ens_dt.fit(x_train, y_train)\n",
    "score = clf_ens_dt.score(x_test, y_test)\n",
    "print(score)\n",
    "scores = cross_val_score(clf_ens_dt, x, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8988802171700034\n",
      "0.8703766542246352\n"
     ]
    }
   ],
   "source": [
    "clf_ens_svc = Ensemble(\n",
    "    DecisionTreeClassifier, 10, random_state=random_state\n",
    ")\n",
    "clf_ens_svc.fit(x_train, y_train)\n",
    "score = clf_ens_svc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
